<!DOCTYPE html>
<html lang="eng">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width">
  <link rel="stylesheet" href="./styles.css">
  <title>Fei Pan @ Univ. of Michigan</title>
</head>
<body>
  <div class='wrapper'>
    <table>
      <tbody><tr>
        <td width="120">
          <img src="./files/fei_bio.jpg">
        </td>
        <td>
          <h2>Fei Pan</h2>
          feipan [at] umich.edu<br>
          <a href="./files/fei_cv.pdf">CV</a> | 
          <a href="https://scholar.google.com/citations?hl=en&user=VGE3DlYAAAAJ"> Google Scholar</a>
        </td>
    </tr>
    </tbody></table>

    <script>
      function showAbstract() {
        var dots = document.getElementById("dots");
        var moreText = document.getElementById("more");
        var btnText = document.getElementById("myBtn");
      
        if (dots.style.display === "none") {
          dots.style.display = "inline";
          btnText.innerHTML = "Abstractaaa"; 
          moreText.style.display = "none";
        } else {
          dots.style.display = "none";
          btnText.innerHTML = "Abstractbbb"; 
          moreText.style.display = "inline";
        }
      }
      </script>      
    
    <p align="justify">I am a Postdoctoral Researcher in the Department of 
      Computer Science at <a href="https://umich.edu/">University of Michigan, Ann Arbor</a>. 
      I am fortunate to work with <a href="https://scholar.google.com/citations?user=uqWkLzMAAAAJ"> Prof. Stella X. Yu</a>. 
      My research lies in Computer Vision and Machine Learning. 
      I am interested in developing large-scale learning algorithms 
        for visual tasks with strong robustness and minimal human supervision.
      I obtained my Ph.D. degree in 2023 supervised by <a href="https://scholar.google.com/citations?user=XA8EOlEAAAAJ&hl=en">Prof. In So Kweon</a> at KAIST. 
      During my Ph.D. study, I've received Qualcomm Innovation Fellowship and Ph.D. scholarship from Robert Bosch GmbH.
    </p>
    <p>
    <strong>Research Interest</strong><br>
      <ul>
        <li>Transfer Learning and Adaptation</li>
        <li>Unsupervised/Self-superivised Learning</li>
        <li>Visual and Language Foundation Models</li>
      </ul>
    </p>

    <h3 id="publications">Publications</h3>
    <!-- <h4 id="2023">2023</h4> -->
    
    <ul>
      <li>
        <!-- Masking-augmented Collaborative Domain Congregation for 
          Multi-target Domain Adaptation in Semantic Segmentation<br>
        <strong>Fei Pan</strong>, Dong He, Xu Yin, Chengshuang Zhang, Munchurl Kim.<br>
        Under Reivew, 2023 <br> -->
        <div class="read-more-container">
          <div class="container">
            <p>
              Masking-augmented Collaborative Domain Congregation for 
              Multi-target Domain Adaptation in Semantic Segmentation<br>
              <strong>Fei Pan</strong>, Dong He, Xu Yin, Chengshuang Zhang, Munchurl Kim.<br>
              Under Reivew, 2023<br>
              <span class="read-more-text">
                This paper addresses the challenges in multi-target domain adaptive segmentation 
                which aims at learning a single model that adapts to multiple diverse target domains. 
                Existing methods show limited performance as they only consider the difference in visual appearance (style) 
                while ignoring the (contextual) variations among multiple target domains. 
                In contrast, we propose a novel approach termed Masking-augmented Collaborative Domain Congregation (MacDC) 
                to handle the style gap and contextual gap altogether. 
                The proposed MacDC comprises two key parts: collaborative domain congregation (CDC) and multi-context masking consistency (MCMC). 
                Our CDC handles the style and contextual gaps among target domains by data mixing, which generates image-level and region-level 
                intermediate domains among target domains. To further strengthen contextual alignment, 
                our MCMC applies a masking-based self-supervised augmentation consistency that enforces the model's understanding of 
                diverse contexts together.
                MacDC directly learns a single model for multi-target domain adaptation without requiring multiple network training and subsequent distillation. 
                Despite its simplicity, MacDC shows efficacy in mitigating the style and contextual gap among multiple target domains and demonstrates 
                superior performance on multi-target domain adaptation for segmentation benchmarks compared to existing state-of-the-art approaches. <br>
              </span>
              <span class="read-more-btn">Abstract</span>
            </p>
            
          </div>
        </div>

        
        <!-- <span>
          This paper addresses the challenges in multi-target domain adaptive segmentation 
            which aims at learning a single model that adapts to multiple diverse target domains. 
          Existing methods show limited performance as they only consider the difference in visual appearance (\textit{style}) 
            while ignoring the \textit{contextual} variations among multiple target domains. 
          In contrast, we propose a novel approach termed Masking-augmented Collaborative Domain Congregation (MacDC) 
            to handle the \textit{style gap} and \textit{contextual gap} altogether. 
          The proposed MacDC comprises two key parts: collaborative domain congregation (CDC) and multi-context masking consistency (MCMC). 
          Our CDC handles the style and contextual gaps among target domains by data mixing, which generates image-level and region-level 
            intermediate domains among target domains. To further strengthen contextual alignment, 
            our MCMC applies a \textit{masking}-based self-supervised augmentation consistency that enforces the model's understanding of 
            diverse contexts together.
           MacDC directly learns a single model for multi-target domain adaptation without requiring multiple network training and subsequent distillation. 
           Despite its simplicity, MacDC shows efficacy in mitigating the style and contextual gap among multiple target domains and demonstrates 
           superior performance on multi-target domain adaptation for segmentation benchmarks compared to existing state-of-the-art approaches.
        </span>
        <button onclick="showAbstract()" id="myBtn">Abstract</button> -->
      </li>
      
      <li>
        <p align="left">
        Fine-grained Background Representation for Weakly Supervised Semantic Segmentation<br>
        Xu Yin, Woobin Im, Dongbo Min, Yuchi Huo, <strong>Fei Pan</strong>, Sungeui Yoon.<br>
        Under Reivew, 2023 <br>
        </p>
      </li>
      <li>
        <p align="left">
          MoDA: Leveraging Motion Prior from Videos for Advancing Unsupervised Domain 
            Adaptation in Semantic Segmentation<br>
          <strong>Fei Pan</strong>*, Xu Yin*, Seokju Lee, Sungeui Yoon, In So Kweon<br>
          Under Review, 2023<br>
        </p>
      </li>
      <li>
        <p align="left">
          ML-BPM: Multi-teacher Learning with Bidirectional Photometric Mixing for Open 
            Compound Domain Adaptation in Semantic Segmentation<br>
          <strong>Fei Pan</strong>, Sungsu Hur, Seokju Lee, Junsik Kim, In So Kweon<br>
          European Conference on Computer Vision (ECCV), 2022
        </p>
      </li>
      <li>
        <p align="left">
          Labeling Where Adapting Fails: Cross-Domain Semantic Segmentation with Point 
            Supervised via Active Learning<br>
          <strong>Fei Pan</strong>, Francois Rameau, Junsik Kim, In So Kweon<br>
          arXiv, 2022
        </p>
      </li>
      <li>
        <p>
          Attentive and Contrastive Learning for Joint Depth and Motion Field Estimation<br>
          Seokju Lee, Francois Rameau, <strong>Fei Pan</strong>, In So Kweon<br>
          International Conference on Computer Vision (ICCV), 2021<br>
        </p>
      </li>
      <li>
        <p>
          Two-phase Pseudo Label Densification for Self-training based Domain Adaptation<br>
          Inkyu Shin, Sanghyun Woo, <strong>Fei Pan</strong>, In So Kweon<br>
          European Conference on Computer Vision (ECCV), 2020<br>
        </p>
      </li>
      <li>
        <p>
          Unsupervised Intra-domain Adaptation for Semantic Segmentation through Self-supervision<br>
          <strong>Fei Pan</strong>, Inkyu Shin, Francois Rameau, Seokju Lee, In So Kweon<br>
          IEEE Computer Vision and Pattern Recognition Conference (CVPR), 2020<br>
        </p>
      </li>
      <li>
        <p>
          Variational Prototyping-Encoder: One-shot Learning with Prototypical Images<br>
          Junsik Kim, Tae-hyun Oh, Seokju Lee, <strong>Fei Pan</strong>, In So Kweon<br>
          IEEE Computer Vision and Pattern Recognition Conference (CVPR), 2019<br>
        </p>
      </li>
      <li>
        <p>
          Driver Drowsiness Detection System Based on Feature Representation Learning Using Various Deep Networks<br>
          Sanghyuk Park, <strong>Fei Pan</strong>, Sunghun Kang, Chang D. Yoo<br>
          Asian Conference on Computer Vision Workshops (ACCVW), 2016<br>
        </p>
      </li>

    </ul>
  
  <script src="script.js"></script>
  <p align="right">
    <small><i>updated by 2023</i></small><br>
  </p>
  
  </div>
</body>
</html>
